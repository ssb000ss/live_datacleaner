import logging

import streamlit as st
import polars as pl

from utils import config
from utils.data_cleaner import (
    clean_special_chars,
    normalize_whitespace,
    lowercase_columns,
    replace_empty_with,
    drop_null_rows,
    drop_duplicates
)
from utils.ui_utils import get_column_display_name


# def clean_columns(
#         ldf: pl.LazyFrame,
#         columns: list[str],
#         regex_pattern: str,
#         to_lowercase: bool = True,
#         nullify_empty: bool = True,
#         empty_value: str | None = None,
# ) -> pl.LazyFrame:
#     if regex_pattern:
#         ldf = ldf.with_columns([
#             pl.col(col)
#             .cast(str)
#             .str.extract_all(regex_pattern)
#             .map_elements(lambda matches: "".join(matches), return_dtype=pl.String)
#             .alias(col)
#             for col in columns
#         ])
#     if to_lowercase:
#         ldf = lowercase_columns(ldf, columns)
#     if nullify_empty:
#         ldf = replace_empty_with(ldf, value=empty_value)
#     return ldf

def clean_columns(
        ldf: pl.LazyFrame,
        columns: list[str],
        regex_pattern: str,
        to_lowercase: bool = True,
        nullify_empty: bool = True,
        empty_value: str | None = None,
) -> pl.LazyFrame:
    logger = logging.getLogger(config.APP_TITLE)
    logger.info(f"–ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–æ–Ω–æ–∫: {columns} —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º: {regex_pattern}")

    try:
        if regex_pattern:
            ldf = ldf.with_columns([
                pl.col(col)
                .cast(pl.Utf8, strict=False)
                .fill_null("")
                .alias(col)
                for col in columns
            ])
            logger.debug(f"–ü—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ Utf8 –∏ –∑–∞–º–µ–Ω–µ–Ω—ã null –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫: {columns}")

            ldf = ldf.with_columns([
                pl.col(col)
                .str.extract_all(regex_pattern)
                .list.eval(pl.element().filter(pl.element().str.len_chars() > 0),
                           parallel=True)  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
                .list.join("")
                .fill_null("")  # –ó–∞–º–µ–Ω–∞ null (–ø—É—Å—Ç—ã—Ö —Å–ø–∏—Å–∫–æ–≤) –Ω–∞ ""
                .cast(pl.Utf8)  # –Ø–≤–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Å—Ç—Ä–æ–∫–µ
                .alias(col)
                for col in columns
            ])
            logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω—ã –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫: {columns}")

        if to_lowercase:
            logger.debug(f"–ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫: {columns}")
            ldf = lowercase_columns(ldf, columns)

        if nullify_empty:
            logger.debug(f"–ó–∞–º–µ–Ω–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ {empty_value} –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫: {columns}")
            ldf = replace_empty_with(ldf, value=empty_value)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ö–µ–º—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        logger.info("–°—Ö–µ–º–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–æ–Ω–æ–∫:")
        for name, dtype in ldf.schema.items():
            logger.info(f"  {name}: {dtype}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫–æ–ª–æ–Ω–æ–∫ {columns}: {e}")
        raise

    logger.info(f"–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ {columns} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    return ldf


def apply_column_cleaning_pipeline(
        ldf: pl.LazyFrame,
        columns_metadata: dict,
        to_lowercase: bool = True,
        nullify_empty: bool = True,
        empty_value: str | None = None,
) -> pl.LazyFrame:
    standalone_columns = [
        col for col, meta in columns_metadata.items()
        if meta.get("mode") == "standalone"
    ]

    ldf = clean_special_chars(ldf)
    ldf = normalize_whitespace(ldf)

    for col in standalone_columns:
        meta = columns_metadata[col]
        display_name = meta.get("display_name", col)
        concatenated = meta.get("concatenated")
        selected_patterns = meta.get("selected_patterns", [])
        detector = st.session_state.pattern_detector
        compiled_pattern = detector.combine_regex(selected_patterns)
        pattern = compiled_pattern.pattern if compiled_pattern else ""

        if not concatenated:
            ldf = clean_columns(
                ldf,
                columns=[col],
                regex_pattern=pattern,
                to_lowercase=to_lowercase,
                nullify_empty=nullify_empty,
                empty_value=empty_value
            )
        else:
            source_columns = concatenated["source_columns"]
            separator = concatenated["separator"]

            ldf = clean_columns(
                ldf,
                columns=source_columns,
                regex_pattern=pattern,
                to_lowercase=to_lowercase,
                nullify_empty=nullify_empty,
                empty_value=empty_value
            )
            ldf = ldf.with_columns([
                pl.concat_str([pl.col(col) for col in source_columns], separator=separator).alias(display_name)
            ])

    exclude_columns = [
        col for col, meta in columns_metadata.items()
        if meta.get("mode") == "exclude"
    ]
    if exclude_columns:
        ldf = ldf.drop(exclude_columns)

    return ldf


def run_full_cleaning():
    if "lazy_df" not in st.session_state or st.session_state.lazy_df is None:
        st.warning("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ —à–∞–≥–µ 1!")
        return

    columns_metadata = st.session_state.columns_data
    ldf = st.session_state.lazy_df

    # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø—É—Å—Ç—ã—Ö
    standalone_columns = [
        col for col in st.session_state.df.columns
        if st.session_state.columns_data[col]["mode"] == "standalone"
    ]

    unique_columns = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º —É–¥–∞–ª—è—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã:",
        options=standalone_columns,
        format_func=get_column_display_name
    )

    not_empty_columns = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º–∏:",
        options=standalone_columns,
        format_func=get_column_display_name
    )

    if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥"):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            logger = logging.getLogger(config.APP_TITLE)
            try:
                ldf = apply_column_cleaning_pipeline(ldf, columns_metadata)

                ldf = drop_duplicates(ldf, unique_columns)

                ldf = drop_null_rows(ldf, not_empty_columns)

                st.session_state.lazy_df = ldf

                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–≤—å—é –±–µ–∑ –ø–æ–ª–Ω–æ–π materialization –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
                st.session_state.df = ldf.fetch(1000)

                st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            except Exception as e:
                logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞")
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞: {e}")
