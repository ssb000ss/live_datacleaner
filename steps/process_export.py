import os
import logging
from pathlib import Path

import streamlit as st
import polars as pl

from utils import config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(config.APP_TITLE)


def rename_columns(ldf: pl.LazyFrame) -> pl.LazyFrame:
    if "columns_data" not in st.session_state:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–ª–æ–Ω–∫–∞—Ö –≤ session_state.columns_data")

    columns_data = st.session_state.columns_data

    included_columns = [
        col for col, data in columns_data.items()
        if data.get("mode") != "exclude" and col in ldf.collect_schema()
    ]

    rename_map = {
        col: columns_data[col]["display_name"]
        for col in included_columns
    }

    renamed_ldf = ldf.select(included_columns).rename(rename_map)

    return renamed_ldf


def step_export_file():
    if "lazy_df" not in st.session_state or st.session_state.lazy_df is None:
        st.error("–ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —à–∞–≥ 1.")
        return

    if "source_file" not in st.session_state or st.session_state.source_file is None:
        st.error("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ –∏–º—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.")
        return

    st.subheader("üì§ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")

    export_format = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞:", ["parquet", "csv"])
    base_export_dir = st.text_input("–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞:", value="exports")

    if export_format == "parquet":
        max_file_size_mb = st.number_input(
            "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ú–ë):", min_value=10, max_value=1000, value=100, step=10
        )
        compression = st.selectbox("–°–∂–∞—Ç–∏–µ Parquet:", ["zstd", "snappy", "gzip", "none"], index=0)

    if st.button("–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å"):
        try:
            original_name = st.session_state.source_file.stem
            target_dir = Path(base_export_dir) / original_name
            target_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"–≠–∫—Å–ø–æ—Ä—Ç–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {target_dir.resolve()}")

            # ‚ö†Ô∏è –í—Å–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ –ª–µ–Ω–∏–≤–æ–º —Ä–µ–∂–∏–º–µ –î–û collect()
            ldf = rename_columns(st.session_state.lazy_df)

            st.info("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å...")
            df = ldf.collect()
            st.write(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {df.height}, –∫–æ–ª–æ–Ω–æ–∫: {df.width}")

            if export_format == "parquet":
                rows_per_chunk = estimate_rows_per_chunk(df, max_file_size_mb)
                num_chunks = (df.height + rows_per_chunk - 1) // rows_per_chunk
                st.write(f"üî¢ –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {num_chunks} (–ø–æ {rows_per_chunk} —Å—Ç—Ä–æ–∫)")

                for i in range(num_chunks):
                    chunk = df.slice(i * rows_per_chunk, rows_per_chunk)
                    filename = target_dir / f"{original_name}_part_{i + 1}.parquet"
                    chunk.write_parquet(
                        filename,
                        compression=None if compression == "none" else compression
                    )
                    logger.info(f"–ó–∞–ø–∏—Å–∞–Ω: {filename.name}")
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {num_chunks} .parquet —Ñ–∞–π–ª–æ–≤ –≤ `{target_dir}`")

            elif export_format == "csv":
                filename = target_dir / f"{original_name}.csv"
                df.write_csv(
                    file=filename,
                    separator="|"
                )
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ CSV: `{filename}`")

        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ")
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {e}")


def estimate_rows_per_chunk(df: pl.DataFrame, target_mb: int) -> int:
    try:
        sample_size = min(10_000, df.height)
        sample = df.head(sample_size)

        sample_path = "/tmp/sample_export.parquet"
        sample.write_parquet(sample_path, compression="zstd")
        size_mb = os.path.getsize(sample_path) / 1024 / 1024
        os.remove(sample_path)

        if size_mb == 0:
            return max(df.height // 4, 100_000)  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–µ—Ñ–æ–ª—Ç

        rows_per_mb = sample_size / size_mb
        return max(int(rows_per_mb * target_mb), 10_000)  # –Ω–µ –º–µ–Ω—å—à–µ 10k

    except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {e}")
        return max(df.height // 4, 100_000)  # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
